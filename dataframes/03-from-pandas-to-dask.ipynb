{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gotcha's from Pandas to Dask\n",
    "\n",
    "This notebook highlights some key differences when transfering code from Pandas to run in a Dask environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start Dask Client for Dashboard\n",
    "\n",
    "Starting the Dask Client is optional.  It will provide a dashboard which \n",
    "is useful to gain insight on the computation.  \n",
    "\n",
    "The link to the dashboard will become visible when you create the client below.  We recommend having it open on one side of your screen while using your notebook on the other side.  This can take some effort to arrange your windows, but seeing them both at the same is very useful when learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"border: 2px solid white;\">\n",
       "<tr>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Client</h3>\n",
       "<ul>\n",
       "  <li><b>Scheduler: </b>tcp://127.0.0.1:43778\n",
       "  <li><b>Dashboard: </b><a href='http://127.0.0.1:8787/status' target='_blank'>http://127.0.0.1:8787/status</a>\n",
       "</ul>\n",
       "</td>\n",
       "<td style=\"vertical-align: top; border: 0px solid white\">\n",
       "<h3>Cluster</h3>\n",
       "<ul>\n",
       "  <li><b>Workers: </b>4</li>\n",
       "  <li><b>Cores: </b>8</li>\n",
       "  <li><b>Memory: </b>67.44 GB</li>\n",
       "</ul>\n",
       "</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<Client: scheduler='tcp://127.0.0.1:43778' processes=4 cores=8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dask.distributed import Client\n",
    "# client = Client(n_workers=1, threads_per_worker=4, processes=False, memory_limit='2GB')\n",
    "client = Client()\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create 2 DataFrames: \n",
    "1. for Dask \n",
    "2. for Pandas  \n",
    "Dask comes with builtin dataset samples.  \n",
    "In order to create a Pandas dataframe all that is needed is to run compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dask versoin: 1.2.0\n",
      "Pandas versoin: 0.24.2\n"
     ]
    }
   ],
   "source": [
    "import dask\n",
    "import pandas as pd\n",
    "print(f'Dask versoin: {dask.__version__}')\n",
    "print(f'Pandas versoin: {pd.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><strong>Dask DataFrame Structure:</strong></div>\n",
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>npartitions=30</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01</th>\n",
       "      <td>int64</td>\n",
       "      <td>object</td>\n",
       "      <td>float64</td>\n",
       "      <td>float64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-02</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-30</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-31</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "<div>Dask Name: make-timeseries, 30 tasks</div>"
      ],
      "text/plain": [
       "Dask DataFrame Structure:\n",
       "                   id    name        x        y\n",
       "npartitions=30                                 \n",
       "2000-01-01      int64  object  float64  float64\n",
       "2000-01-02        ...     ...      ...      ...\n",
       "...               ...     ...      ...      ...\n",
       "2000-01-30        ...     ...      ...      ...\n",
       "2000-01-31        ...     ...      ...      ...\n",
       "Dask Name: make-timeseries, 30 tasks"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf = dask.datasets.timeseries()\n",
    "ddf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Remember `Dask dataframes` are **lazy** thus in order to see the result we need to run compute() \n",
    " (or head which runs under the hood compute()) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00</th>\n",
       "      <td>1053</td>\n",
       "      <td>Edith</td>\n",
       "      <td>-0.082485</td>\n",
       "      <td>0.126788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:01</th>\n",
       "      <td>992</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>-0.292002</td>\n",
       "      <td>0.814259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:02</th>\n",
       "      <td>991</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>-0.435019</td>\n",
       "      <td>-0.923308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:03</th>\n",
       "      <td>998</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>-0.164077</td>\n",
       "      <td>0.195232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:04</th>\n",
       "      <td>989</td>\n",
       "      <td>Norbert</td>\n",
       "      <td>0.343440</td>\n",
       "      <td>-0.787839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id     name         x         y\n",
       "timestamp                                             \n",
       "2000-01-01 00:00:00  1053    Edith -0.082485  0.126788\n",
       "2000-01-01 00:00:01   992    Zelda -0.292002  0.814259\n",
       "2000-01-01 00:00:02   991   Yvonne -0.435019 -0.923308\n",
       "2000-01-01 00:00:03   998   Xavier -0.164077  0.195232\n",
       "2000-01-01 00:00:04   989  Norbert  0.343440 -0.787839"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timestamp</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:00</th>\n",
       "      <td>1053</td>\n",
       "      <td>Edith</td>\n",
       "      <td>-0.082485</td>\n",
       "      <td>0.126788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:01</th>\n",
       "      <td>992</td>\n",
       "      <td>Zelda</td>\n",
       "      <td>-0.292002</td>\n",
       "      <td>0.814259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:02</th>\n",
       "      <td>991</td>\n",
       "      <td>Yvonne</td>\n",
       "      <td>-0.435019</td>\n",
       "      <td>-0.923308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:03</th>\n",
       "      <td>998</td>\n",
       "      <td>Xavier</td>\n",
       "      <td>-0.164077</td>\n",
       "      <td>0.195232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2000-01-01 00:00:04</th>\n",
       "      <td>989</td>\n",
       "      <td>Norbert</td>\n",
       "      <td>0.343440</td>\n",
       "      <td>-0.787839</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       id     name         x         y\n",
       "timestamp                                             \n",
       "2000-01-01 00:00:00  1053    Edith -0.082485  0.126788\n",
       "2000-01-01 00:00:01   992    Zelda -0.292002  0.814259\n",
       "2000-01-01 00:00:02   991   Yvonne -0.435019 -0.923308\n",
       "2000-01-01 00:00:03   998   Xavier -0.164077  0.195232\n",
       "2000-01-01 00:00:04   989  Norbert  0.343440 -0.787839"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf = ddf.compute()  # create a pandas dataframe\n",
    "print(type(pdf))\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have both `dataframes` we can start to compair the interactions with them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Conceptual shift - from Update to Insert/Delete\n",
    "Dask does not update - thus no arguments such as \"inplace= True\" which exist in Pandas.  \n",
    "For more detials see [issue#653 on github](https://github.com/dask/dask/issues/653)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Rename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "print(pdf.columns)\n",
    "pdf.rename(columns={'id':'ID','name':'Name','x':'coor_x', 'y':'coor_y'},inplace=True)\n",
    "pdf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "# Must update using the correct sequence of the columns\n",
    "print(ddf.columns)\n",
    "ddf.columns = ['ID','Name','coor_x','coor_y']\n",
    "ddf.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Column munipilations  \n",
    "There are several diffrences when manimuplating data. mose of which require to ran a couple of lines (instead of one-liners)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert index into Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "pdf = pdf.assign(Time=pd.to_datetime(pdf.index).time)\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "ddf = ddf.assign(Time=ddf.index)\n",
    "ddf['Time'] = ddf['Time'].dt.time\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Drop NA on column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "pdf = pdf.assign(colna = None)\n",
    "print(pdf.head())\n",
    "pdf.dropna(axis=1, how='all', inplace=True)\n",
    "print(pdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "ddf = ddf.assign(colna = None)\n",
    "print(ddf.head())\n",
    "if ddf.colna.isnull().all().compute() == True:   # check if all values in column are Null - VERY slow\n",
    "    ddf = ddf.drop(labels=['colna'],axis=1)\n",
    "print(ddf.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.4 Reset Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "pdf.reset_index(drop=True, inplace=True)\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dask is in a development mode\n",
    "thus there bugs that are fixed all the time   \n",
    "e.g. [reset_index fails when index is named ](https://github.com/dask/dask/pull/4509)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This currently fails without reseting the dataframe......\n",
    "ddf = dask.datasets.timeseries()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "ddf.index.name = None   # workaround\n",
    "ddf = ddf.reset_index()\n",
    "ddf['Time'] = ddf['timestamp'].dt.time\n",
    "ddf = ddf.drop(labels=['timestamp'], axis=1 )\n",
    "ddf.columns = ['ID','Name','coor_x','coor_y','Time']\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Reads/Save files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with pandas and dask preferable try and work with parquet.  \n",
    "Even so when working with Dask - the files can be read with multiple workers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas\n",
    "!mkdir data\n",
    "pdf.to_csv('data/pdf_single_file.csv')\n",
    "!ls data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "# 1. notice the '*' to allow for multiple file renaming. all kwrgs are applicable\n",
    "# 2. notice that the path to the directory may change based on the location of the running notebook\n",
    "ddf.to_csv('data/pd2dd/ddf*.csv', index = False)\n",
    "!ls data/pd2dd/\n",
    "# to fild number of partitions use dask.dataframe.npartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on an [answer from stack overflow](https://stackoverflow.com/questions/20906474/import-multiple-csv-files-into-pandas-and-concatenate-into-one-dataframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas \n",
    "path = r'data/'                     # use your path\n",
    "all_files = glob.glob(os.path.join(path, \"*.csv\"))     # advisable to use os.path.join as this makes concatenation OS independent\n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "ddf = dask.dataframe.read_csv('data/pd2dd/ddf*.csv')\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most `kwarg` are available for reading and writing \n",
    "e.g. \n",
    "ddf = dask.dataframe.read_csv('data/pd2dd/ddf*.csv', compression='gzip', header none)\n",
    "However `nrows` is not available\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Group By\n",
    "In addition to the notebook example that is in the repository - \n",
    "This is another example how to try to eliminate the use of `groupby.apply`  \n",
    "In this example we are grouping by coloumns into unique list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare pandas dataframe\n",
    "pdf = pdf.assign(Time=pd.to_datetime(pdf.index).time)\n",
    "pdf['seconds'] = pdf.Time.astype(str).str[-2:]\n",
    "pdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas preperations\n",
    "def set_list_att(x: dask.dataframe.Series):\n",
    "        return list(set([item for item in x.values]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# pandas option 1 using apply\n",
    "pdf_gb = pdf.groupby(pdf.Name)\n",
    "gp_col = ['ID', 'seconds']\n",
    "list_ser_gb = [pdf_gb[att_col_gr].apply(set_list_att) for att_col_gr in gp_col]\n",
    "df_edge_att = pdf_gb.size().to_frame(name=\"Weight\")\n",
    "for ser in list_ser_gb:\n",
    "        df_edge_att = df_edge_att.join(ser.to_frame(), how='left')        \n",
    "df_edge_att.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# pandas option 2 using lambda\n",
    "pdf_gb = pdf.groupby(pdf.Name)\n",
    "gp_col = ['ID', 'seconds']\n",
    "list_ser_gb = [pdf_gb[att_col_gr].apply(lambda x: list(set(x.to_list()))) for att_col_gr in gp_col]\n",
    "df_edge_att = pdf_gb.size().to_frame(name=\"Weight\")\n",
    "for ser in list_ser_gb:\n",
    "        df_edge_att = df_edge_att.join(ser.to_frame(), how='left')        \n",
    "df_edge_att.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In any case sometimes using Pandas is more efficiante (assuming that you can load all the data into the RAM).  \n",
    "In this case Pandas is faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare dask dataframe\n",
    "ddf['seconds'] = ddf.Time.astype(str).str[-2:]\n",
    "ddf = client.persist(ddf)\n",
    "ddf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Dask option1 using apply\n",
    "# notice the meta argument in the apply function\n",
    "df_gb = ddf.groupby(ddf.Name)\n",
    "gp_col = ['ID', 'seconds']\n",
    "list_ser_gb = [df_gb[att_col_gr].apply(set_list_att\n",
    "                                      ,meta=pd.Series(dtype='object', name=f'{att_col_gr}_att')) \n",
    "               for att_col_gr in gp_col]\n",
    "df_edge_att = df_gb.size().to_frame(name=\"Weight\")\n",
    "for ser in list_ser_gb:\n",
    "        df_edge_att = df_edge_att.join(ser.to_frame(), how='left')        \n",
    "df_edge_att.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using [dask custom aggregation](https://docs.dask.org/en/latest/dataframe-api.html?highlight=dropna#dask.dataframe.groupby.Aggregation) is consideribly better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dask\n",
    "# some preperations\n",
    "import itertools\n",
    "custom_agg = dask.dataframe.Aggregation(\n",
    "    'custom_agg', \n",
    "    lambda s: s.apply(set), \n",
    "    lambda s: s.apply(lambda chunks: list(set(itertools.chain.from_iterable(chunks)))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "# Dask option1 using apply\n",
    "df_gb = ddf.groupby(ddf.Name)\n",
    "gp_col = ['ID', 'seconds']\n",
    "list_ser_gb = [df_gb[att_col_gr].agg(custom_agg) for att_col_gr in gp_col]\n",
    "df_edge_att = df_gb.size().to_frame(name=\"Weight\")\n",
    "for ser in list_ser_gb:\n",
    "        df_edge_att = df_edge_att.join(ser.to_frame(), how='left')        \n",
    "df_edge_att.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## 4. Consider using Persist\n",
    "Since Dask is lazy - it may ran the **entire** graph (again) even if it already ran part of it in order to generate a result \n",
    "in a previous cell.  \n",
    "```python\n",
    "ddf = client.persist(ddf)\n",
    "```\n",
    "This is different from Pandas which once a variable was created it will keep all data in memory.  \n",
    "Additional information can be read in this [stackoverflow issue](https://stackoverflow.com/questions/45941528/how-to-efficiently-send-a-large-numpy-array-to-the-cluster-with-dask-array/45941529#45941529) or see an exampel in [this post](http://matthewrocklin.com/blog/work/2017/01/12/dask-dataframes)   \n",
    "This concept should also  be used when running a code within a script (rather then a jupyter notebook) which incoperates a loop logic within the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Debugging\n",
    "Debugging my be more challenging since\n",
    "1. when using a client - mutliprocessing is complecated\n",
    "2. sometime introducing a faulty command into a graph (such as in a jupyter notebook) requirues to cache-out the graph and start the process from the begining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
